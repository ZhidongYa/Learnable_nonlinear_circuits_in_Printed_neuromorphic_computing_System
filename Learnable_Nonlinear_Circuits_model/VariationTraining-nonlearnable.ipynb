{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29513307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net level\n",
    "import pNN_NetLevel_LNC_variation as pNN\n",
    "\n",
    "# packages\n",
    "import os\n",
    "import math\n",
    "import torch\n",
    "import random\n",
    "import pickle\n",
    "import calendar\n",
    "import numpy as np\n",
    "import config\n",
    "import training_together_variation as training \n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "torch.set_default_tensor_type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89ca9016",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = os.listdir('./dataset')\n",
    "datasets = [f for f in datasets if (f.startswith('Dataset') and f.endswith('.p'))] \n",
    "#datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36602eb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_acuteinflammation_seed_0_nonlearnable1\n",
      "| Epoch:        0 | Valid accuracy: 0.86957 | Valid loss: 0.676321149 |\n",
      "| Epoch:     5000 | Valid accuracy: 1.00000 | Valid loss: 0.000000000 |\n",
      "dataset_balancescale_seed_0_nonlearnable1\n",
      "| Epoch:        0 | Valid accuracy: 0.41935 | Valid loss: 0.713952243 |\n",
      "| Epoch:     5000 | Valid accuracy: 0.96774 | Valid loss: 0.048945166 |\n",
      "dataset_breastcancerwisc_seed_0_nonlearnable1\n",
      "| Epoch:        0 | Valid accuracy: 0.66187 | Valid loss: 0.698530138 |\n",
      "| Epoch:     5000 | Valid accuracy: 0.94964 | Valid loss: 0.090649277 |\n",
      "dataset_cardiotocography3clases_seed_0_nonlearnable1\n",
      "| Epoch:        0 | Valid accuracy: 0.74528 | Valid loss: 0.702790558 |\n",
      "| Epoch:     5000 | Valid accuracy: 0.90566 | Valid loss: 0.169152781 |\n",
      "dataset_energyy1_seed_0_nonlearnable1\n",
      "| Epoch:        0 | Valid accuracy: 0.20261 | Valid loss: 0.725977361 |\n",
      "| Epoch:     5000 | Valid accuracy: 0.84314 | Valid loss: 0.240390152 |\n",
      "| Epoch:    10000 | Valid accuracy: 0.87582 | Valid loss: 0.237709463 |\n",
      "dataset_energyy2_seed_0_nonlearnable1\n",
      "| Epoch:        0 | Valid accuracy: 0.26797 | Valid loss: 0.714964867 |\n",
      "| Epoch:     5000 | Valid accuracy: 0.91503 | Valid loss: 0.156471372 |\n",
      "dataset_iris_seed_0_nonlearnable1\n",
      "| Epoch:        0 | Valid accuracy: 0.68966 | Valid loss: 0.699851811 |\n",
      "| Epoch:     5000 | Valid accuracy: 0.93103 | Valid loss: 0.060909629 |\n",
      "dataset_mammographic_seed_0_nonlearnable1\n",
      "| Epoch:        0 | Valid accuracy: 0.56545 | Valid loss: 0.696022928 |\n",
      "| Epoch:     5000 | Valid accuracy: 0.83770 | Valid loss: 0.268224239 |\n",
      "dataset_Pendigits_seed_0_nonlearnable1\n",
      "| Epoch:        0 | Valid accuracy: 0.11146 | Valid loss: 0.808271766 |\n",
      "| Epoch:     5000 | Valid accuracy: 0.38944 | Valid loss: 0.542116046 |\n",
      "| Epoch:    10000 | Valid accuracy: 0.40127 | Valid loss: 0.538267255 |\n",
      "dataset_seeds_seed_0_nonlearnable1\n",
      "| Epoch:        0 | Valid accuracy: 0.48780 | Valid loss: 0.703708291 |\n",
      "| Epoch:     5000 | Valid accuracy: 0.92683 | Valid loss: 0.167483777 |\n",
      "dataset_tictactoe_seed_0_nonlearnable1\n",
      "| Epoch:        0 | Valid accuracy: 0.28272 | Valid loss: 0.710462570 |\n",
      "| Epoch:     5000 | Valid accuracy: 0.80105 | Valid loss: 0.342081189 |\n",
      "dataset_vertebralcolumn2clases_seed_0_nonlearnable1\n",
      "| Epoch:        0 | Valid accuracy: 0.32787 | Valid loss: 0.714037538 |\n",
      "| Epoch:     5000 | Valid accuracy: 0.86885 | Valid loss: 0.270163655 |\n",
      "| Epoch:    10000 | Valid accuracy: 0.86885 | Valid loss: 0.270237476 |\n",
      "dataset_vertebralcolumn3clases_seed_0_nonlearnable1\n",
      "| Epoch:        0 | Valid accuracy: 0.55738 | Valid loss: 0.700025201 |\n",
      "| Epoch:     5000 | Valid accuracy: 0.80328 | Valid loss: 0.303330094 |\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#result = torch.zeros((13, 1, 10))\n",
    "lrs = [0]\n",
    "for i in range(len(datasets)):\n",
    "    dataset = datasets[i]\n",
    "    datapath = os.path.join(f'./dataset/{dataset}')\n",
    "    with open(datapath, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    X_train    = data['X_train']\n",
    "    y_train    = data['y_train']\n",
    "    X_valid    = data['X_valid']\n",
    "    y_valid    = data['y_valid']\n",
    "    X_test     = data['X_test']\n",
    "    y_test     = data['y_test']\n",
    "    data_name  = data['name']\n",
    "\n",
    "    N_class    = data['n_class']\n",
    "    N_feature  = data['n_feature']\n",
    "    N_train    = X_train.shape[0]\n",
    "    N_valid    = X_valid.shape[0]\n",
    "    N_test     = X_test.shape[0]\n",
    "    \n",
    "    # generate tensordataset\n",
    "    trainset = TensorDataset(X_train, y_train)\n",
    "    validset = TensorDataset(X_valid, y_valid)\n",
    "    testset  = TensorDataset(X_test, y_test)\n",
    "\n",
    "    # batch\n",
    "    train_loader = DataLoader(trainset, batch_size=N_train)\n",
    "    valid_loader = DataLoader(validset, batch_size=N_valid)\n",
    "    test_loader  = DataLoader(testset,  batch_size=N_test)\n",
    "    \n",
    "    for j in range(len(lrs)):\n",
    "        lr = lrs[j]\n",
    "        \n",
    "        for n in range(10):     \n",
    "            \n",
    "        setup = f'dataset_{data_name}_seed_{seed}_nonlearnable1'\n",
    "        print(setup)\n",
    "            \n",
    "        if os.path.exists(f'./results_variation/pNN_{setup}'):\n",
    "            print('File exists, pass.')\n",
    "        else:\n",
    "            torch.manual_seed(seed)\n",
    "            model = pNN.pNN([N_feature, 3, N_class], 1, 0)\n",
    "    \n",
    "            optimizer = torch.optim.Adam([{'params':model.GetParam('theta_'),'lr':1e-1},\n",
    "                                  {'params':model.GetParam('eta_'), 'lr':lr},\n",
    "                                  {'params':model.GetParam('inv_'),'lr':lr}])\n",
    "    \n",
    "    \n",
    "            NN, acc_valid = training.training_pNN(model, train_loader, valid_loader, optimizer, pNN.lossfunction)\n",
    "                #result[i,j,n] = acc_valid\n",
    "            torch.save(NN, f'./results_variation/pNN_{setup}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8db693",
   "metadata": {},
   "source": [
    "## valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e35394f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "acc = torch.zeros((13, 1, 10))\n",
    "#lrs = [0.0005]\n",
    "for i in range(len(datasets)):\n",
    "    dataset = datasets[i]\n",
    "    datapath = os.path.join(f'./dataset/{dataset}')\n",
    "    with open(datapath, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    X_train    = data['X_train']\n",
    "    y_train    = data['y_train']\n",
    "    X_valid    = data['X_valid']\n",
    "    y_valid    = data['y_valid']\n",
    "    X_test     = data['X_test']\n",
    "    y_test     = data['y_test']\n",
    "    data_name  = data['name']\n",
    "\n",
    "    N_class    = data['n_class']\n",
    "    N_feature  = data['n_feature']\n",
    "    N_train    = X_train.shape[0]\n",
    "    N_valid    = X_valid.shape[0]\n",
    "    N_test     = X_test.shape[0]\n",
    "    \n",
    "    # generate tensordataset\n",
    "    trainset = TensorDataset(X_train, y_train)\n",
    "    validset = TensorDataset(X_valid, y_valid)\n",
    "    testset  = TensorDataset(X_test, y_test)\n",
    "\n",
    "    # batch\n",
    "    train_loader = DataLoader(trainset, batch_size=N_train)\n",
    "    valid_loader = DataLoader(validset, batch_size=N_valid)\n",
    "    test_loader  = DataLoader(testset,  batch_size=N_test)\n",
    "    \n",
    "    for j in range(len(lrs)):\n",
    "        lr = lrs[j]\n",
    "        \n",
    "        for n in range(10):\n",
    "            seed = n      \n",
    "            setup = f'dataset_{data_name}_seed_{seed}_nonlearnable1'\n",
    "            model = torch.load(f'./results_variation/pNN_{setup}')\n",
    "            \n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for X_valid, y_valid in valid_loader:\n",
    "                \n",
    "                    prediction_valid = model(X_valid)\n",
    "                    #acc_valid = lossfunction(prediction_valid, y_valid)\n",
    "                    yhat_valid = torch.argmax(prediction_valid.data, 2)\n",
    "                \n",
    "                    yy_valid = y_valid.repeat(prediction_valid.shape[0], 1)\n",
    "                    valid_correct = torch.sum(yhat_valid == yy_valid.data)\n",
    "                    acc_valid = valid_correct / (y_valid.numel() * prediction_valid.shape[0])\n",
    "                    acc[i,j,n] = acc_valid\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcdf4bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
